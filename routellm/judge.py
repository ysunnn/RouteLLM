import json

from typing import Optional, Dict, Any
import ollama


def _build_judging_prompt(user_prompt: str, week_response: str) -> str:
    return f"""
    You are an expert AI response evaluator. Assess the quality of the following response generated by LLM model.
    User Prompt:
    {user_prompt}
    
    Model Response:
    {week_response}
    
    Evaluate Response based on following metrics and give a score between 0.0 (worst) and 1.0 (best) representing
    the overall quality: accuracy, relevance, completeness, clarity, coherence, depth, conciseness, and style.
    Respond ONLY with a JSON object like: {{"score": 0.55}}.
    """


class Judge:
    def __init__(
            self,
            model_type: str = "local",
            model_name: str = "llama3",
            threshold: float = 0.85,
            api_key: Optional[str] = None
    ):
        self.model_type = model_type
        self.model_name = model_name
        self.threshold = threshold
        self.api_key = api_key

    def _query_local(self, prompt: str) -> Dict[str, Any]:
        response = ollama.chat(
            model=self.model_name,
            messages=[{"role": "user", "content": prompt}],
            stream=False
        )
        content = response['message']['content']
        return json.loads(content)

    def judge(self, user_prompt: str, weak_response: str) -> float:
        judging_prompt = _build_judging_prompt(user_prompt, weak_response)
        result = self._query_local(judging_prompt)

        print(f"Result: {result}")

        return result["score"]

    def should_reroute(self, score: float) -> bool:
        return score < self.threshold
